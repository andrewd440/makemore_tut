{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-03-25 16:18:53--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8002::154, 2606:50c0:8001::154, 2606:50c0:8003::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8002::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1115394 (1.1M) [text/plain]\n",
      "Saving to: ‘input_shakespeare.txt’\n",
      "\n",
      "input_shakespeare.t 100%[===================>]   1.06M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2023-03-25 16:18:54 (10.7 MB/s) - ‘input_shakespeare.txt’ saved [1115394/1115394]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt -O input_shakespeare.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input_shakespeare.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read() # should be simple plain text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input length in chars: 1115394\n"
     ]
    }
   ],
   "source": [
    "print('input length in chars:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab length: 65\n",
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(list(set(text)))\n",
    "vocab_size = len(vocab)\n",
    "print('vocab length:', vocab_size)\n",
    "print(''.join(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 43, 50, 50, 53]\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "stoi = {c: i for i, c in enumerate(vocab)}\n",
    "itos = {i: c for i, c in enumerate(vocab)}\n",
    "encode = lambda x: [stoi[c] for c in x]\n",
    "decode = lambda x: ''.join([itos[c] for c in x])\n",
    "print(encode('hello'))\n",
    "print(decode(encode('hello')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = encode(text)\n",
    "\n",
    "n_split = int(0.9 * len(data))\n",
    "train_data = data[:n_split]\n",
    "val_data = data[n_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 14, 43, 44, 53, 56, 43, 1, 61, 43, 1, 54, 56, 53, 41, 43, 43, 42, 1, 39, 52, 63, 1, 44, 59, 56, 58, 46, 43, 56, 6, 1, 46, 43, 39, 56, 1, 51, 43, 1, 57, 54, 43, 39, 49, 8, 0, 0, 13, 50, 50, 10, 0, 31, 54, 43, 39, 49, 6, 1, 57, 54, 43, 39, 49, 8, 0, 0, 18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 37, 53, 59]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 14, 43]\n"
     ]
    }
   ],
   "source": [
    "block_size = 8\n",
    "print(train_data[:block_size+9])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example result\n",
    "[context] --> output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18] --> 47\n",
      "[18, 47] --> 56\n",
      "[18, 47, 56] --> 57\n",
      "[18, 47, 56, 57] --> 58\n",
      "[18, 47, 56, 57, 58] --> 1\n",
      "[18, 47, 56, 57, 58, 1] --> 15\n",
      "[18, 47, 56, 57, 58, 1, 15] --> 47\n",
      "[18, 47, 56, 57, 58, 1, 15, 47] --> 58\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for i in range(block_size):\n",
    "    print(x[:i+1], '-->', y[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example batch and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imputs shape: torch.Size([4, 8])\n",
      "targets shape: torch.Size([4, 8])\n",
      "inputs (first batch): tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]], device='cuda:0')\n",
      "targets (first batch): tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]], device='cuda:0')\n",
      "-----\n",
      "context --> target\n",
      "[24] --> 43\n",
      "[24, 43] --> 58\n",
      "[24, 43, 58] --> 5\n",
      "[24, 43, 58, 5] --> 57\n",
      "[24, 43, 58, 5, 57] --> 1\n",
      "[24, 43, 58, 5, 57, 1] --> 46\n",
      "[24, 43, 58, 5, 57, 1, 46] --> 43\n",
      "[24, 43, 58, 5, 57, 1, 46, 43] --> 39\n",
      "[44] --> 53\n",
      "[44, 53] --> 56\n",
      "[44, 53, 56] --> 1\n",
      "[44, 53, 56, 1] --> 58\n",
      "[44, 53, 56, 1, 58] --> 46\n",
      "[44, 53, 56, 1, 58, 46] --> 39\n",
      "[44, 53, 56, 1, 58, 46, 39] --> 58\n",
      "[44, 53, 56, 1, 58, 46, 39, 58] --> 1\n",
      "[52] --> 58\n",
      "[52, 58] --> 1\n",
      "[52, 58, 1] --> 58\n",
      "[52, 58, 1, 58] --> 46\n",
      "[52, 58, 1, 58, 46] --> 39\n",
      "[52, 58, 1, 58, 46, 39] --> 58\n",
      "[52, 58, 1, 58, 46, 39, 58] --> 1\n",
      "[52, 58, 1, 58, 46, 39, 58, 1] --> 46\n",
      "[25] --> 17\n",
      "[25, 17] --> 27\n",
      "[25, 17, 27] --> 10\n",
      "[25, 17, 27, 10] --> 0\n",
      "[25, 17, 27, 10, 0] --> 21\n",
      "[25, 17, 27, 10, 0, 21] --> 1\n",
      "[25, 17, 27, 10, 0, 21, 1] --> 54\n",
      "[25, 17, 27, 10, 0, 21, 1, 54] --> 39\n"
     ]
    }
   ],
   "source": [
    "# seed random number generator for torch\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data if split == 'val' else None\n",
    "    \n",
    "    if data is None:\n",
    "        raise ValueError('split must be either train or val')\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.tensor([data[i:i+block_size] for i in ix]).to(device)\n",
    "    y = torch.tensor([data[i+1:i+block_size+1] for i in ix]).to(device)\n",
    "    return x, y\n",
    "    \n",
    "xb, yb = get_batch('train')\n",
    "print(f'imputs shape: {xb.shape}')\n",
    "print(f'targets shape: {yb.shape}')\n",
    "print(f'inputs (first batch):', xb)\n",
    "print(f'targets (first batch):', yb)\n",
    "print('-----')\n",
    "print('context --> target')\n",
    "for b in range(batch_size):\n",
    "    for i in range(block_size):\n",
    "        print(xb[b, 0:i+1].tolist(), '-->', yb[b, i].item())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BigramLanguageModel(\n",
      "  (embed): Embedding(65, 65)\n",
      ")\n",
      "torch.Size([32, 65])\n",
      "tensor([[ 1.6347, -0.0518,  0.4996,  ...,  0.2432,  1.1519,  0.9950],\n",
      "        [ 0.3418, -0.9276,  1.2381,  ...,  1.5018, -0.5266,  0.2354],\n",
      "        [ 0.1479, -0.4333,  0.5203,  ...,  0.3302,  1.5454,  1.3778],\n",
      "        ...,\n",
      "        [-0.5693, -0.0735,  0.7743,  ..., -0.0815, -1.1445, -0.0623],\n",
      "        [ 0.4658, -0.2573, -1.0673,  ...,  1.2439,  1.3471,  1.6910],\n",
      "        [-0.4553,  0.0139,  0.9309,  ...,  0.0290, -0.7568,  0.8701]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Expected Loss: log(vocab_size) -> 4.174387454986572\n",
      "loss.shape=torch.Size([])\n",
      "loss=tensor(5.0364, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        \n",
    "    def forward(self, x, targets=None):\n",
    "        x = self.embed(x)\n",
    "        logits = x\n",
    "\n",
    "        loss = None\n",
    "        if targets != None:\n",
    "            B,T,C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        if targets is None:\n",
    "            return logits\n",
    "        else:\n",
    "            return logits, loss\n",
    "    \n",
    "    def generate(self, x, n):\n",
    "        # input is B x T\n",
    "        for i in range(n):\n",
    "            logits = self(x) # B x T x C\n",
    "            # only use last prediction\n",
    "            logits = logits[:, -1, :] # B x C\n",
    "            # sample from distribution\n",
    "            probs = F.softmax(logits, dim=-1) # B x C\n",
    "            # sample next token\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # B x 1\n",
    "            x = torch.cat([x, idx_next], dim=1) # B x (T+1)\n",
    "\n",
    "        return x\n",
    "    \n",
    "n_embed = vocab_size\n",
    "model = BigramLanguageModel(vocab_size, n_embed).to(device)\n",
    "print(model)\n",
    "pred, loss = model(xb, yb)\n",
    "print(pred.shape)\n",
    "print(pred)\n",
    "\n",
    "# expect loss to be around log(vocab_size) on random predictions\n",
    "print(f'Expected Loss: log(vocab_size) -> {torch.log(torch.tensor(vocab_size))}')\n",
    "print(f'{loss.shape=}')\n",
    "print(f'{loss=}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test init samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.size(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 18])\n",
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43, 57, 55,  3, 11, 58, 44, 14, 44, 30, 27],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58,  2, 36, 41, 31, 19, 60, 30, 44, 15, 36],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1, 62, 51, 27,  4, 55, 21, 16, 50, 11,  2],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54, 11, 58, 22, 29, 46, 34,  0, 63, 34,  0]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"Let's hesq$;tfBfRO\",\n",
       " 'for that!XcSGvRfCX',\n",
       " 'nt that xmO&qIDl;!',\n",
       " 'MEO:\\nI p;tJQhV\\nyV\\n']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = model.generate(xb, 10)\n",
    "print(gen.shape)\n",
    "print(gen)\n",
    "[decode(gen[i].tolist()) for i in range(batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]], device='cuda:0')\n",
      "\n",
      "kNdcuwdZZTkOMl;,ertK\n",
      "w:!PLCkMBbeA$3:XaSGJO-3p&M-c?KL3auhpFYVXJFhNNNuhq$OMxv.tbVFYdXlrFZaAeNuw:cPPyRE\n",
      "\n",
      "lc-T nA,e!ngm MWtJferEFQ \n",
      "yQfQwsZENdpkS:WRfL-kZbMtviGvRmt'vK&$DjCerSm bns\n",
      "yCb,-cKknvTHMvyu&l;tMu'Rfg\n",
      "\n",
      "O\n",
      "nG?RPhBOUjuhpd\n",
      "CTYui3pYCGPimnqj.aajGK,eM\n",
      "Eeoql-RoY.WvsZEQ:B;'vDUqheFREN?zkyX'It;C n:;Gr.ypkdoPl?Kl\n",
      "\n",
      "ug;tkN'a3ePBPUfpkl;zUZuAFGbrFSiXs\n",
      "lMOH-aZpdei&$ydu'wDSR;BaV\n",
      "!xQKkZWQ$Bjtzkl;aaniq!3fzg-$n-U3QH&I&$RN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = torch.zeros(batch_size, 1, dtype=torch.long).to(device)\n",
    "print(idx)\n",
    "[print(p) for p in [decode(pred) for pred in model.generate(idx, 100).tolist()]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# construct optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step=0, loss=tensor(4.6816, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=10, loss=tensor(4.6154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=20, loss=tensor(4.7026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=30, loss=tensor(4.5495, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=40, loss=tensor(4.6024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=50, loss=tensor(4.6507, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=60, loss=tensor(4.5948, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=70, loss=tensor(4.5310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=80, loss=tensor(4.5669, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=90, loss=tensor(4.6026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=100, loss=tensor(4.4530, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=110, loss=tensor(4.5275, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=120, loss=tensor(4.4396, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=130, loss=tensor(4.5409, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=140, loss=tensor(4.5587, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=150, loss=tensor(4.4245, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=160, loss=tensor(4.4538, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=170, loss=tensor(4.5437, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=180, loss=tensor(4.3781, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=190, loss=tensor(4.3629, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=200, loss=tensor(4.4292, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=210, loss=tensor(4.4259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=220, loss=tensor(4.4415, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=230, loss=tensor(4.4072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=240, loss=tensor(4.3039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=250, loss=tensor(4.3307, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=260, loss=tensor(4.4302, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=270, loss=tensor(4.3941, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=280, loss=tensor(4.3408, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=290, loss=tensor(4.2359, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=300, loss=tensor(4.3411, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=310, loss=tensor(4.3524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=320, loss=tensor(4.3161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=330, loss=tensor(4.2349, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=340, loss=tensor(4.2431, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=350, loss=tensor(4.1748, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=360, loss=tensor(4.2196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=370, loss=tensor(4.1874, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=380, loss=tensor(4.2204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=390, loss=tensor(4.3059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=400, loss=tensor(4.1649, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=410, loss=tensor(4.2467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=420, loss=tensor(4.1677, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=430, loss=tensor(4.2705, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=440, loss=tensor(4.1594, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=450, loss=tensor(4.0931, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=460, loss=tensor(4.1340, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=470, loss=tensor(4.1287, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=480, loss=tensor(4.2241, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=490, loss=tensor(4.1173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=500, loss=tensor(4.1344, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=510, loss=tensor(4.1908, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=520, loss=tensor(4.0752, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=530, loss=tensor(4.0342, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=540, loss=tensor(4.0921, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=550, loss=tensor(4.1497, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=560, loss=tensor(3.9897, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=570, loss=tensor(4.0323, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=580, loss=tensor(4.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=590, loss=tensor(4.0209, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=600, loss=tensor(3.9425, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=610, loss=tensor(3.9962, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=620, loss=tensor(3.9825, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=630, loss=tensor(4.0458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=640, loss=tensor(4.0377, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=650, loss=tensor(3.9641, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=660, loss=tensor(3.9528, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=670, loss=tensor(4.1193, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=680, loss=tensor(3.9122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=690, loss=tensor(3.9706, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=700, loss=tensor(3.9262, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=710, loss=tensor(4.0153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=720, loss=tensor(4.0111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=730, loss=tensor(3.9389, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=740, loss=tensor(3.9254, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=750, loss=tensor(3.9870, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=760, loss=tensor(3.8255, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=770, loss=tensor(3.7973, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=780, loss=tensor(3.9046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=790, loss=tensor(3.7812, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=800, loss=tensor(3.8634, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=810, loss=tensor(3.7190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=820, loss=tensor(3.9179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=830, loss=tensor(3.8033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=840, loss=tensor(3.7566, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=850, loss=tensor(3.8721, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=860, loss=tensor(3.8632, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=870, loss=tensor(3.7599, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=880, loss=tensor(3.7186, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=890, loss=tensor(3.7481, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=900, loss=tensor(3.7774, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=910, loss=tensor(3.6878, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=920, loss=tensor(3.6573, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=930, loss=tensor(3.6611, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=940, loss=tensor(3.6119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=950, loss=tensor(3.7860, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=960, loss=tensor(3.6822, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=970, loss=tensor(3.7692, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=980, loss=tensor(3.7129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=990, loss=tensor(3.7355, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1000, loss=tensor(3.6312, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1010, loss=tensor(3.7037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1020, loss=tensor(3.5893, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1030, loss=tensor(3.7333, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1040, loss=tensor(3.6724, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1050, loss=tensor(3.6876, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1060, loss=tensor(3.7009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1070, loss=tensor(3.6073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1080, loss=tensor(3.6207, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1090, loss=tensor(3.5482, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1100, loss=tensor(3.5710, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1110, loss=tensor(3.6302, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1120, loss=tensor(3.5860, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1130, loss=tensor(3.5773, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1140, loss=tensor(3.6419, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1150, loss=tensor(3.5734, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1160, loss=tensor(3.5888, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1170, loss=tensor(3.6501, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1180, loss=tensor(3.5161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1190, loss=tensor(3.4866, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1200, loss=tensor(3.5701, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1210, loss=tensor(3.4612, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1220, loss=tensor(3.6328, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1230, loss=tensor(3.5505, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1240, loss=tensor(3.5561, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1250, loss=tensor(3.5643, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1260, loss=tensor(3.5117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1270, loss=tensor(3.5300, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1280, loss=tensor(3.4547, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1290, loss=tensor(3.5950, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1300, loss=tensor(3.3616, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1310, loss=tensor(3.6529, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1320, loss=tensor(3.4336, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1330, loss=tensor(3.4288, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1340, loss=tensor(3.5142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1350, loss=tensor(3.4775, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1360, loss=tensor(3.4158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1370, loss=tensor(3.5279, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1380, loss=tensor(3.4394, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1390, loss=tensor(3.3736, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1400, loss=tensor(3.4419, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1410, loss=tensor(3.3644, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1420, loss=tensor(3.5187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1430, loss=tensor(3.4501, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1440, loss=tensor(3.3700, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1450, loss=tensor(3.4281, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1460, loss=tensor(3.3489, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1470, loss=tensor(3.4299, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1480, loss=tensor(3.4451, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1490, loss=tensor(3.4059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1500, loss=tensor(3.3763, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1510, loss=tensor(3.2773, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1520, loss=tensor(3.4192, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1530, loss=tensor(3.5046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1540, loss=tensor(3.3434, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1550, loss=tensor(3.3890, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1560, loss=tensor(3.3675, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1570, loss=tensor(3.3063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1580, loss=tensor(3.2795, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1590, loss=tensor(3.4389, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1600, loss=tensor(3.3014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1610, loss=tensor(3.3464, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1620, loss=tensor(3.3626, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1630, loss=tensor(3.3534, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1640, loss=tensor(3.2312, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1650, loss=tensor(3.2580, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1660, loss=tensor(3.2800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1670, loss=tensor(3.2088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1680, loss=tensor(3.2410, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1690, loss=tensor(3.3574, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1700, loss=tensor(3.2213, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1710, loss=tensor(3.3213, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1720, loss=tensor(3.2418, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1730, loss=tensor(3.3229, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1740, loss=tensor(3.2477, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1750, loss=tensor(3.2542, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1760, loss=tensor(3.2890, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1770, loss=tensor(3.2424, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1780, loss=tensor(3.3267, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1790, loss=tensor(3.2437, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1800, loss=tensor(3.2888, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1810, loss=tensor(3.1774, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1820, loss=tensor(3.2582, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1830, loss=tensor(3.1799, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1840, loss=tensor(3.2078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1850, loss=tensor(3.2831, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1860, loss=tensor(3.2433, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1870, loss=tensor(3.1694, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1880, loss=tensor(3.2467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1890, loss=tensor(3.1286, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1900, loss=tensor(3.1512, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1910, loss=tensor(3.0497, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1920, loss=tensor(3.1049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1930, loss=tensor(3.2004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1940, loss=tensor(3.0860, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1950, loss=tensor(3.1674, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1960, loss=tensor(3.1420, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1970, loss=tensor(3.1282, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1980, loss=tensor(3.2136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=1990, loss=tensor(3.1740, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2000, loss=tensor(3.1586, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2010, loss=tensor(3.1743, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2020, loss=tensor(3.1019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2030, loss=tensor(3.0595, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2040, loss=tensor(3.1051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2050, loss=tensor(3.1371, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2060, loss=tensor(3.0809, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2070, loss=tensor(3.0985, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2080, loss=tensor(3.1841, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2090, loss=tensor(3.1269, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2100, loss=tensor(3.1419, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2110, loss=tensor(3.0289, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2120, loss=tensor(2.9848, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2130, loss=tensor(3.1381, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2140, loss=tensor(3.0700, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2150, loss=tensor(3.0054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2160, loss=tensor(3.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2170, loss=tensor(3.0583, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2180, loss=tensor(3.0475, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2190, loss=tensor(3.0913, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2200, loss=tensor(2.9783, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2210, loss=tensor(3.0524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2220, loss=tensor(3.0246, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2230, loss=tensor(3.0860, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2240, loss=tensor(3.0303, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2250, loss=tensor(2.9856, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2260, loss=tensor(2.9963, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2270, loss=tensor(3.0701, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2280, loss=tensor(3.0148, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2290, loss=tensor(3.0044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2300, loss=tensor(3.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2310, loss=tensor(3.0073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2320, loss=tensor(2.9577, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2330, loss=tensor(2.9726, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2340, loss=tensor(2.8957, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2350, loss=tensor(3.0122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2360, loss=tensor(2.9980, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2370, loss=tensor(2.9758, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2380, loss=tensor(2.9116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2390, loss=tensor(3.0106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2400, loss=tensor(3.0821, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2410, loss=tensor(3.0697, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2420, loss=tensor(2.9653, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2430, loss=tensor(2.8977, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2440, loss=tensor(2.8742, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2450, loss=tensor(2.9943, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2460, loss=tensor(2.9446, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2470, loss=tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2480, loss=tensor(2.9627, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2490, loss=tensor(2.9785, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2500, loss=tensor(3.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2510, loss=tensor(2.9547, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2520, loss=tensor(2.9047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2530, loss=tensor(2.9353, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2540, loss=tensor(3.0260, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2550, loss=tensor(2.8551, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2560, loss=tensor(3.0626, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2570, loss=tensor(2.9255, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2580, loss=tensor(2.9275, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2590, loss=tensor(2.8348, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2600, loss=tensor(2.8554, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2610, loss=tensor(2.9090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2620, loss=tensor(2.8561, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2630, loss=tensor(2.8126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2640, loss=tensor(2.8525, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2650, loss=tensor(2.8880, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2660, loss=tensor(2.8640, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2670, loss=tensor(2.8447, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2680, loss=tensor(2.9716, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2690, loss=tensor(2.9001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2700, loss=tensor(2.9015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2710, loss=tensor(2.9084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2720, loss=tensor(2.7695, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2730, loss=tensor(2.9175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2740, loss=tensor(2.8981, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2750, loss=tensor(2.8701, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2760, loss=tensor(2.9705, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2770, loss=tensor(2.8194, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2780, loss=tensor(2.8011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2790, loss=tensor(2.8418, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2800, loss=tensor(2.8985, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2810, loss=tensor(2.9021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2820, loss=tensor(2.9404, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2830, loss=tensor(2.8200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2840, loss=tensor(2.8212, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2850, loss=tensor(2.8352, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2860, loss=tensor(2.8965, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2870, loss=tensor(2.8345, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2880, loss=tensor(2.7682, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2890, loss=tensor(2.7600, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2900, loss=tensor(2.8921, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2910, loss=tensor(2.7919, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2920, loss=tensor(2.7559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2930, loss=tensor(2.7909, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2940, loss=tensor(2.7934, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2950, loss=tensor(2.8320, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2960, loss=tensor(2.7770, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2970, loss=tensor(2.8380, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2980, loss=tensor(2.8566, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=2990, loss=tensor(2.7042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3000, loss=tensor(2.7085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3010, loss=tensor(2.7613, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3020, loss=tensor(2.7834, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3030, loss=tensor(2.7528, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3040, loss=tensor(2.7234, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3050, loss=tensor(2.8245, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3060, loss=tensor(2.7967, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3070, loss=tensor(2.9024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3080, loss=tensor(2.7395, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3090, loss=tensor(2.8109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3100, loss=tensor(2.9008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3110, loss=tensor(2.8060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3120, loss=tensor(2.7535, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3130, loss=tensor(2.9644, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3140, loss=tensor(2.8491, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3150, loss=tensor(2.7700, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3160, loss=tensor(2.7102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3170, loss=tensor(2.8712, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3180, loss=tensor(2.7162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3190, loss=tensor(2.7376, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3200, loss=tensor(2.6206, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3210, loss=tensor(2.7390, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3220, loss=tensor(2.6271, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3230, loss=tensor(2.8152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3240, loss=tensor(2.7536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3250, loss=tensor(2.8070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3260, loss=tensor(2.7187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3270, loss=tensor(2.6686, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3280, loss=tensor(2.8138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3290, loss=tensor(2.7664, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3300, loss=tensor(2.7606, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3310, loss=tensor(2.7090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3320, loss=tensor(2.7082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3330, loss=tensor(2.7474, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3340, loss=tensor(2.7370, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3350, loss=tensor(2.7590, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3360, loss=tensor(2.7216, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3370, loss=tensor(2.6640, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3380, loss=tensor(2.7791, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3390, loss=tensor(2.5999, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3400, loss=tensor(2.7567, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3410, loss=tensor(2.6320, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3420, loss=tensor(2.7568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3430, loss=tensor(2.7157, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3440, loss=tensor(2.6994, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3450, loss=tensor(2.6646, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3460, loss=tensor(2.6667, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3470, loss=tensor(2.7780, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3480, loss=tensor(2.6935, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3490, loss=tensor(2.7578, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3500, loss=tensor(2.6534, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3510, loss=tensor(2.6874, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3520, loss=tensor(2.7083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3530, loss=tensor(2.7406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3540, loss=tensor(2.7382, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3550, loss=tensor(2.6594, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3560, loss=tensor(2.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3570, loss=tensor(2.6887, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3580, loss=tensor(2.5736, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3590, loss=tensor(2.6090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3600, loss=tensor(2.8243, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3610, loss=tensor(2.4984, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3620, loss=tensor(2.5539, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3630, loss=tensor(2.6685, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3640, loss=tensor(2.6302, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3650, loss=tensor(2.7757, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3660, loss=tensor(2.7060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3670, loss=tensor(2.7320, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3680, loss=tensor(2.7809, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3690, loss=tensor(2.6720, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3700, loss=tensor(2.6271, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3710, loss=tensor(2.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3720, loss=tensor(2.6593, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3730, loss=tensor(2.7542, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3740, loss=tensor(2.7228, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3750, loss=tensor(2.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3760, loss=tensor(2.6155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3770, loss=tensor(2.7559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3780, loss=tensor(2.8365, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3790, loss=tensor(2.5508, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3800, loss=tensor(2.7249, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3810, loss=tensor(2.6848, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3820, loss=tensor(2.5970, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3830, loss=tensor(2.6025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3840, loss=tensor(2.6464, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3850, loss=tensor(2.6776, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3860, loss=tensor(2.5942, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3870, loss=tensor(2.6668, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3880, loss=tensor(2.6106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3890, loss=tensor(2.6943, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3900, loss=tensor(2.5986, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3910, loss=tensor(2.6970, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3920, loss=tensor(2.5698, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3930, loss=tensor(2.6317, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3940, loss=tensor(2.7125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3950, loss=tensor(2.7338, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3960, loss=tensor(2.6652, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3970, loss=tensor(2.6189, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3980, loss=tensor(2.5666, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=3990, loss=tensor(2.6465, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4000, loss=tensor(2.5327, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4010, loss=tensor(2.6451, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4020, loss=tensor(2.6671, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4030, loss=tensor(2.5696, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4040, loss=tensor(2.4862, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4050, loss=tensor(2.5111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4060, loss=tensor(2.7380, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4070, loss=tensor(2.7099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4080, loss=tensor(2.6014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4090, loss=tensor(2.6447, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4100, loss=tensor(2.7008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4110, loss=tensor(2.5720, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4120, loss=tensor(2.5463, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4130, loss=tensor(2.6913, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4140, loss=tensor(2.7157, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4150, loss=tensor(2.5445, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4160, loss=tensor(2.4654, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4170, loss=tensor(2.5807, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4180, loss=tensor(2.5157, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4190, loss=tensor(2.4864, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4200, loss=tensor(2.6053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4210, loss=tensor(2.5783, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4220, loss=tensor(2.6575, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4230, loss=tensor(2.6668, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4240, loss=tensor(2.4998, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4250, loss=tensor(2.6846, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4260, loss=tensor(2.5308, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4270, loss=tensor(2.6670, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4280, loss=tensor(2.5214, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4290, loss=tensor(2.5994, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4300, loss=tensor(2.5669, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4310, loss=tensor(2.6466, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4320, loss=tensor(2.6187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4330, loss=tensor(2.5672, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4340, loss=tensor(2.6418, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4350, loss=tensor(2.5364, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4360, loss=tensor(2.7197, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4370, loss=tensor(2.6047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4380, loss=tensor(2.5603, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4390, loss=tensor(2.5047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4400, loss=tensor(2.6398, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4410, loss=tensor(2.5225, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4420, loss=tensor(2.6071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4430, loss=tensor(2.5527, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4440, loss=tensor(2.6008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4450, loss=tensor(2.6681, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4460, loss=tensor(2.6187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4470, loss=tensor(2.4630, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4480, loss=tensor(2.6292, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4490, loss=tensor(2.6176, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4500, loss=tensor(2.4611, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4510, loss=tensor(2.6198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4520, loss=tensor(2.5569, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4530, loss=tensor(2.5580, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4540, loss=tensor(2.6225, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4550, loss=tensor(2.5329, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4560, loss=tensor(2.5935, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4570, loss=tensor(2.6338, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4580, loss=tensor(2.7960, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4590, loss=tensor(2.5182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4600, loss=tensor(2.6729, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4610, loss=tensor(2.5454, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4620, loss=tensor(2.6186, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4630, loss=tensor(2.6174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4640, loss=tensor(2.6350, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4650, loss=tensor(2.4944, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4660, loss=tensor(2.4841, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4670, loss=tensor(2.5743, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4680, loss=tensor(2.5203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4690, loss=tensor(2.7204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4700, loss=tensor(2.7498, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4710, loss=tensor(2.5051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4720, loss=tensor(2.5939, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4730, loss=tensor(2.5730, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4740, loss=tensor(2.6292, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4750, loss=tensor(2.6011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4760, loss=tensor(2.7285, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4770, loss=tensor(2.5047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4780, loss=tensor(2.5599, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4790, loss=tensor(2.5865, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4800, loss=tensor(2.4569, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4810, loss=tensor(2.6145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4820, loss=tensor(2.5644, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4830, loss=tensor(2.4931, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4840, loss=tensor(2.7999, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4850, loss=tensor(2.6198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4860, loss=tensor(2.5940, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4870, loss=tensor(2.5575, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4880, loss=tensor(2.4755, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4890, loss=tensor(2.5410, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4900, loss=tensor(2.5543, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4910, loss=tensor(2.6324, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4920, loss=tensor(2.5554, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4930, loss=tensor(2.4925, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4940, loss=tensor(2.6427, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4950, loss=tensor(2.5982, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4960, loss=tensor(2.5881, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4970, loss=tensor(2.6493, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4980, loss=tensor(2.6745, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=4990, loss=tensor(2.4299, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5000, loss=tensor(2.4811, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5010, loss=tensor(2.5582, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5020, loss=tensor(2.6508, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5030, loss=tensor(2.5274, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5040, loss=tensor(2.5054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5050, loss=tensor(2.6036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5060, loss=tensor(2.6445, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5070, loss=tensor(2.5483, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5080, loss=tensor(2.5107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5090, loss=tensor(2.6458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5100, loss=tensor(2.6536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5110, loss=tensor(2.4727, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5120, loss=tensor(2.4547, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5130, loss=tensor(2.5287, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5140, loss=tensor(2.4884, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5150, loss=tensor(2.4953, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5160, loss=tensor(2.6618, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5170, loss=tensor(2.4960, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5180, loss=tensor(2.6473, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5190, loss=tensor(2.4839, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5200, loss=tensor(2.6382, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5210, loss=tensor(2.5068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5220, loss=tensor(2.6776, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5230, loss=tensor(2.5271, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5240, loss=tensor(2.5060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5250, loss=tensor(2.5188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5260, loss=tensor(2.4626, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5270, loss=tensor(2.5733, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5280, loss=tensor(2.5532, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5290, loss=tensor(2.5383, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5300, loss=tensor(2.5350, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5310, loss=tensor(2.5632, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5320, loss=tensor(2.6195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5330, loss=tensor(2.3950, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5340, loss=tensor(2.5411, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5350, loss=tensor(2.5155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5360, loss=tensor(2.5150, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5370, loss=tensor(2.5016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5380, loss=tensor(2.3498, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5390, loss=tensor(2.5833, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5400, loss=tensor(2.5089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5410, loss=tensor(2.4482, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5420, loss=tensor(2.5778, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5430, loss=tensor(2.5600, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5440, loss=tensor(2.6831, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5450, loss=tensor(2.6863, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5460, loss=tensor(2.4341, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5470, loss=tensor(2.5652, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5480, loss=tensor(2.4423, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5490, loss=tensor(2.6492, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5500, loss=tensor(2.5440, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5510, loss=tensor(2.5763, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5520, loss=tensor(2.4537, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5530, loss=tensor(2.7091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5540, loss=tensor(2.5290, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5550, loss=tensor(2.6623, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5560, loss=tensor(2.5189, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5570, loss=tensor(2.5730, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5580, loss=tensor(2.6807, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5590, loss=tensor(2.6645, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5600, loss=tensor(2.4978, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5610, loss=tensor(2.5080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5620, loss=tensor(2.4878, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5630, loss=tensor(2.5470, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5640, loss=tensor(2.4086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5650, loss=tensor(2.5713, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5660, loss=tensor(2.5033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5670, loss=tensor(2.5222, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5680, loss=tensor(2.4790, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5690, loss=tensor(2.6596, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5700, loss=tensor(2.4803, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5710, loss=tensor(2.4482, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5720, loss=tensor(2.5187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5730, loss=tensor(2.4561, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5740, loss=tensor(2.5596, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5750, loss=tensor(2.5208, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5760, loss=tensor(2.6144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5770, loss=tensor(2.3686, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5780, loss=tensor(2.6221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5790, loss=tensor(2.5145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5800, loss=tensor(2.5291, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5810, loss=tensor(2.4147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5820, loss=tensor(2.4446, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5830, loss=tensor(2.3975, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5840, loss=tensor(2.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5850, loss=tensor(2.5426, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5860, loss=tensor(2.5563, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5870, loss=tensor(2.4404, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5880, loss=tensor(2.3716, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5890, loss=tensor(2.6224, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5900, loss=tensor(2.6052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5910, loss=tensor(2.5302, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5920, loss=tensor(2.5258, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5930, loss=tensor(2.4969, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5940, loss=tensor(2.5535, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5950, loss=tensor(2.4799, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5960, loss=tensor(2.5600, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5970, loss=tensor(2.4428, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5980, loss=tensor(2.3868, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=5990, loss=tensor(2.5685, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6000, loss=tensor(2.4536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6010, loss=tensor(2.4970, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6020, loss=tensor(2.4905, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6030, loss=tensor(2.5015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6040, loss=tensor(2.5493, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6050, loss=tensor(2.5318, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6060, loss=tensor(2.5399, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6070, loss=tensor(2.5942, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6080, loss=tensor(2.4432, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6090, loss=tensor(2.4928, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6100, loss=tensor(2.4792, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6110, loss=tensor(2.4849, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6120, loss=tensor(2.5548, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6130, loss=tensor(2.5292, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6140, loss=tensor(2.5663, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6150, loss=tensor(2.5014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6160, loss=tensor(2.4277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6170, loss=tensor(2.5529, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6180, loss=tensor(2.6203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6190, loss=tensor(2.5773, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6200, loss=tensor(2.5291, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6210, loss=tensor(2.4576, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6220, loss=tensor(2.5489, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6230, loss=tensor(2.4924, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6240, loss=tensor(2.5350, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6250, loss=tensor(2.5394, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6260, loss=tensor(2.7438, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6270, loss=tensor(2.5189, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6280, loss=tensor(2.4558, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6290, loss=tensor(2.5369, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6300, loss=tensor(2.5672, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6310, loss=tensor(2.5178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6320, loss=tensor(2.5092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6330, loss=tensor(2.5277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6340, loss=tensor(2.4931, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6350, loss=tensor(2.4315, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6360, loss=tensor(2.4407, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6370, loss=tensor(2.4283, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6380, loss=tensor(2.5587, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6390, loss=tensor(2.5333, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6400, loss=tensor(2.5036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6410, loss=tensor(2.5617, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6420, loss=tensor(2.5407, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6430, loss=tensor(2.6049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6440, loss=tensor(2.5200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6450, loss=tensor(2.4593, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6460, loss=tensor(2.4094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6470, loss=tensor(2.3329, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6480, loss=tensor(2.4878, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6490, loss=tensor(2.5874, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6500, loss=tensor(2.4243, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6510, loss=tensor(2.5726, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6520, loss=tensor(2.3949, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6530, loss=tensor(2.5444, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6540, loss=tensor(2.3668, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6550, loss=tensor(2.5129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6560, loss=tensor(2.5042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6570, loss=tensor(2.4952, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6580, loss=tensor(2.4673, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6590, loss=tensor(2.4318, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6600, loss=tensor(2.4283, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6610, loss=tensor(2.4960, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6620, loss=tensor(2.4230, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6630, loss=tensor(2.4538, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6640, loss=tensor(2.5167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6650, loss=tensor(2.6211, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6660, loss=tensor(2.4277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6670, loss=tensor(2.4879, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6680, loss=tensor(2.4660, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6690, loss=tensor(2.4933, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6700, loss=tensor(2.6267, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6710, loss=tensor(2.4865, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6720, loss=tensor(2.6200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6730, loss=tensor(2.4549, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6740, loss=tensor(2.3390, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6750, loss=tensor(2.6123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6760, loss=tensor(2.5780, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6770, loss=tensor(2.5148, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6780, loss=tensor(2.4779, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6790, loss=tensor(2.5150, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6800, loss=tensor(2.4440, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6810, loss=tensor(2.5233, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6820, loss=tensor(2.5631, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6830, loss=tensor(2.5151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6840, loss=tensor(2.5739, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6850, loss=tensor(2.5457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6860, loss=tensor(2.5734, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6870, loss=tensor(2.4438, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6880, loss=tensor(2.6378, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6890, loss=tensor(2.5417, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6900, loss=tensor(2.5874, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6910, loss=tensor(2.3378, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6920, loss=tensor(2.4847, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6930, loss=tensor(2.4902, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6940, loss=tensor(2.3586, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6950, loss=tensor(2.4581, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6960, loss=tensor(2.5608, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6970, loss=tensor(2.4898, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6980, loss=tensor(2.5209, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=6990, loss=tensor(2.5222, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7000, loss=tensor(2.4442, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7010, loss=tensor(2.5193, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7020, loss=tensor(2.4805, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7030, loss=tensor(2.5007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7040, loss=tensor(2.5103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7050, loss=tensor(2.5505, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7060, loss=tensor(2.4640, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7070, loss=tensor(2.5004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7080, loss=tensor(2.3802, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7090, loss=tensor(2.5241, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7100, loss=tensor(2.5251, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7110, loss=tensor(2.5422, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7120, loss=tensor(2.4893, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7130, loss=tensor(2.4416, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7140, loss=tensor(2.4487, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7150, loss=tensor(2.4283, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7160, loss=tensor(2.4175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7170, loss=tensor(2.4574, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7180, loss=tensor(2.4335, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7190, loss=tensor(2.5061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7200, loss=tensor(2.5313, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7210, loss=tensor(2.5305, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7220, loss=tensor(2.3622, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7230, loss=tensor(2.4451, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7240, loss=tensor(2.4671, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7250, loss=tensor(2.5365, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7260, loss=tensor(2.4333, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7270, loss=tensor(2.5357, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7280, loss=tensor(2.4063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7290, loss=tensor(2.5928, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7300, loss=tensor(2.5252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7310, loss=tensor(2.4448, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7320, loss=tensor(2.6653, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7330, loss=tensor(2.4735, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7340, loss=tensor(2.4414, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7350, loss=tensor(2.5731, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7360, loss=tensor(2.5828, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7370, loss=tensor(2.4400, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7380, loss=tensor(2.4872, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7390, loss=tensor(2.5241, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7400, loss=tensor(2.5094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7410, loss=tensor(2.4856, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7420, loss=tensor(2.4540, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7430, loss=tensor(2.5283, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7440, loss=tensor(2.4701, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7450, loss=tensor(2.4458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7460, loss=tensor(2.5894, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7470, loss=tensor(2.5007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7480, loss=tensor(2.4745, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7490, loss=tensor(2.5191, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7500, loss=tensor(2.4903, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7510, loss=tensor(2.4727, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7520, loss=tensor(2.4593, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7530, loss=tensor(2.4423, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7540, loss=tensor(2.4661, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7550, loss=tensor(2.4361, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7560, loss=tensor(2.5718, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7570, loss=tensor(2.5237, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7580, loss=tensor(2.3943, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7590, loss=tensor(2.3434, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7600, loss=tensor(2.4820, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7610, loss=tensor(2.5192, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7620, loss=tensor(2.6610, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7630, loss=tensor(2.4881, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7640, loss=tensor(2.4244, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7650, loss=tensor(2.4800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7660, loss=tensor(2.4410, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7670, loss=tensor(2.4558, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7680, loss=tensor(2.5095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7690, loss=tensor(2.5238, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7700, loss=tensor(2.5311, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7710, loss=tensor(2.4353, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7720, loss=tensor(2.5709, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7730, loss=tensor(2.5632, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7740, loss=tensor(2.5696, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7750, loss=tensor(2.3686, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7760, loss=tensor(2.4152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7770, loss=tensor(2.5314, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7780, loss=tensor(2.5257, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7790, loss=tensor(2.5962, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7800, loss=tensor(2.4250, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7810, loss=tensor(2.5897, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7820, loss=tensor(2.4690, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7830, loss=tensor(2.4488, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7840, loss=tensor(2.3765, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7850, loss=tensor(2.3925, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7860, loss=tensor(2.5435, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7870, loss=tensor(2.5335, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7880, loss=tensor(2.4761, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7890, loss=tensor(2.4030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7900, loss=tensor(2.5340, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7910, loss=tensor(2.5364, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7920, loss=tensor(2.5465, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7930, loss=tensor(2.4818, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7940, loss=tensor(2.4921, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7950, loss=tensor(2.4332, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7960, loss=tensor(2.4500, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7970, loss=tensor(2.3388, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7980, loss=tensor(2.3927, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=7990, loss=tensor(2.4653, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8000, loss=tensor(2.4807, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8010, loss=tensor(2.5472, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8020, loss=tensor(2.4687, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8030, loss=tensor(2.3261, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8040, loss=tensor(2.4702, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8050, loss=tensor(2.5775, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8060, loss=tensor(2.5122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8070, loss=tensor(2.5253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8080, loss=tensor(2.5285, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8090, loss=tensor(2.5829, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8100, loss=tensor(2.4605, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8110, loss=tensor(2.5354, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8120, loss=tensor(2.5389, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8130, loss=tensor(2.6674, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8140, loss=tensor(2.4476, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8150, loss=tensor(2.3629, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8160, loss=tensor(2.4656, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8170, loss=tensor(2.5380, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8180, loss=tensor(2.5564, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8190, loss=tensor(2.5028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8200, loss=tensor(2.4915, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8210, loss=tensor(2.5303, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8220, loss=tensor(2.4292, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8230, loss=tensor(2.4701, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8240, loss=tensor(2.4772, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8250, loss=tensor(2.5368, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8260, loss=tensor(2.3914, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8270, loss=tensor(2.4452, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8280, loss=tensor(2.3806, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8290, loss=tensor(2.4599, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8300, loss=tensor(2.2793, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8310, loss=tensor(2.6456, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8320, loss=tensor(2.2992, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8330, loss=tensor(2.5029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8340, loss=tensor(2.4911, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8350, loss=tensor(2.4443, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8360, loss=tensor(2.5125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8370, loss=tensor(2.4391, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8380, loss=tensor(2.4982, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8390, loss=tensor(2.4749, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8400, loss=tensor(2.5379, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8410, loss=tensor(2.4105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8420, loss=tensor(2.4484, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8430, loss=tensor(2.4951, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8440, loss=tensor(2.3738, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8450, loss=tensor(2.3742, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8460, loss=tensor(2.4322, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8470, loss=tensor(2.4853, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8480, loss=tensor(2.3904, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8490, loss=tensor(2.5760, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8500, loss=tensor(2.4991, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8510, loss=tensor(2.4718, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8520, loss=tensor(2.5392, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8530, loss=tensor(2.3067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8540, loss=tensor(2.4657, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8550, loss=tensor(2.3813, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8560, loss=tensor(2.5106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8570, loss=tensor(2.3845, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8580, loss=tensor(2.4006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8590, loss=tensor(2.4784, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8600, loss=tensor(2.5514, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8610, loss=tensor(2.4924, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8620, loss=tensor(2.4050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8630, loss=tensor(2.4910, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8640, loss=tensor(2.4491, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8650, loss=tensor(2.5384, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8660, loss=tensor(2.5260, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8670, loss=tensor(2.4919, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8680, loss=tensor(2.4834, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8690, loss=tensor(2.4853, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8700, loss=tensor(2.5169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8710, loss=tensor(2.4044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8720, loss=tensor(2.4380, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8730, loss=tensor(2.5072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8740, loss=tensor(2.4531, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8750, loss=tensor(2.4010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8760, loss=tensor(2.5196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8770, loss=tensor(2.5574, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8780, loss=tensor(2.3772, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8790, loss=tensor(2.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8800, loss=tensor(2.5168, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8810, loss=tensor(2.4346, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8820, loss=tensor(2.3628, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8830, loss=tensor(2.5948, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8840, loss=tensor(2.4353, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8850, loss=tensor(2.5151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8860, loss=tensor(2.3434, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8870, loss=tensor(2.4589, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8880, loss=tensor(2.3803, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8890, loss=tensor(2.4639, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8900, loss=tensor(2.4332, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8910, loss=tensor(2.5263, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8920, loss=tensor(2.5300, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8930, loss=tensor(2.4980, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8940, loss=tensor(2.4462, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8950, loss=tensor(2.4988, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8960, loss=tensor(2.4008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8970, loss=tensor(2.4744, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8980, loss=tensor(2.5623, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=8990, loss=tensor(2.4791, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9000, loss=tensor(2.4001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9010, loss=tensor(2.4956, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9020, loss=tensor(2.3432, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9030, loss=tensor(2.3806, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9040, loss=tensor(2.5562, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9050, loss=tensor(2.5051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9060, loss=tensor(2.5007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9070, loss=tensor(2.4656, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9080, loss=tensor(2.4752, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9090, loss=tensor(2.4298, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9100, loss=tensor(2.5747, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9110, loss=tensor(2.4787, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9120, loss=tensor(2.4391, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9130, loss=tensor(2.4507, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9140, loss=tensor(2.5459, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9150, loss=tensor(2.5428, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9160, loss=tensor(2.4032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9170, loss=tensor(2.5056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9180, loss=tensor(2.3809, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9190, loss=tensor(2.4122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9200, loss=tensor(2.4483, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9210, loss=tensor(2.4973, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9220, loss=tensor(2.4819, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9230, loss=tensor(2.5328, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9240, loss=tensor(2.3973, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9250, loss=tensor(2.4937, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9260, loss=tensor(2.4416, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9270, loss=tensor(2.4131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9280, loss=tensor(2.4626, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9290, loss=tensor(2.5525, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9300, loss=tensor(2.5718, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9310, loss=tensor(2.4258, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9320, loss=tensor(2.5173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9330, loss=tensor(2.5707, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9340, loss=tensor(2.5347, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9350, loss=tensor(2.3495, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9360, loss=tensor(2.4600, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9370, loss=tensor(2.4441, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9380, loss=tensor(2.4267, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9390, loss=tensor(2.5591, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9400, loss=tensor(2.3732, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9410, loss=tensor(2.4896, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9420, loss=tensor(2.6312, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9430, loss=tensor(2.5402, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9440, loss=tensor(2.5165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9450, loss=tensor(2.5017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9460, loss=tensor(2.4826, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9470, loss=tensor(2.4334, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9480, loss=tensor(2.4988, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9490, loss=tensor(2.4954, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9500, loss=tensor(2.3924, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9510, loss=tensor(2.4884, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9520, loss=tensor(2.5037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9530, loss=tensor(2.5098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9540, loss=tensor(2.4135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9550, loss=tensor(2.4433, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9560, loss=tensor(2.4967, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9570, loss=tensor(2.5207, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9580, loss=tensor(2.5223, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9590, loss=tensor(2.3427, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9600, loss=tensor(2.3991, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9610, loss=tensor(2.5511, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9620, loss=tensor(2.4862, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9630, loss=tensor(2.5035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9640, loss=tensor(2.3917, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9650, loss=tensor(2.5473, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9660, loss=tensor(2.3935, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9670, loss=tensor(2.5615, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9680, loss=tensor(2.3388, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9690, loss=tensor(2.4476, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9700, loss=tensor(2.5293, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9710, loss=tensor(2.4780, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9720, loss=tensor(2.4173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9730, loss=tensor(2.4772, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9740, loss=tensor(2.4341, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9750, loss=tensor(2.5692, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9760, loss=tensor(2.3244, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9770, loss=tensor(2.4728, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9780, loss=tensor(2.4269, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9790, loss=tensor(2.5396, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9800, loss=tensor(2.5446, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9810, loss=tensor(2.5340, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9820, loss=tensor(2.4502, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9830, loss=tensor(2.4947, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9840, loss=tensor(2.4297, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9850, loss=tensor(2.5172, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9860, loss=tensor(2.3830, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9870, loss=tensor(2.4624, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9880, loss=tensor(2.4792, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9890, loss=tensor(2.5534, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9900, loss=tensor(2.4256, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9910, loss=tensor(2.5323, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9920, loss=tensor(2.4938, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9930, loss=tensor(2.5033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9940, loss=tensor(2.3660, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9950, loss=tensor(2.4251, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9960, loss=tensor(2.5149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9970, loss=tensor(2.4443, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9980, loss=tensor(2.5373, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "step=9990, loss=tensor(2.6118, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "step_count = 10000\n",
    "for step in range(step_count):\n",
    "    xb, yb = get_batch('train')\n",
    "    _, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if step % 10 == 0:\n",
    "        print(f'{step=}, {loss=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Thanstarom oroup\n",
      "Yowhthetof isth ble mil; dill, ath iree sengmin lat Heriliovets, and Win nghire yombousel lind me l.\n",
      "HAshe ce hiry ptupr aisspllw y.\n",
      "Hurindu n Boopetelaves\n",
      "MPORDis, d mothakleo Windo \n"
     ]
    }
   ],
   "source": [
    "print(decode(model.generate(torch.zeros((1,1), device=device, dtype=torch.long), 200)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "makemore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
